Algorytm centroidow to metoda optymalizacji istniejacego podzialu (grupowania) zbioru obiektow. TAK
Algorytm selekcji za pomoca kola ruletki w algorytmie genetycznym moze spowodowac opanowanie populacji potomnej kopiami najgorszego osobnika. TAK
Algorytm wstecznej propagacji daje globalnie optymalne wartosci wag po przejsciu wszystkich przykladow treningowych. NIE
Algorytm wychladzania jest w stanie dokladnie rozwiazac dowolny problem NP-trudny w czasie wielomianowym. NIE
Algorytmu ewolucyjne rozpatruja wiele przykladowych rozwiazan problemu i zwykle powielaja lepsze z nich. TAK
Blad ostatniej warstwy sieci neuronowej otrzymuje sie porownujac odpowiedz sieci z prawidlowa odpowiedzia podana przez nauczyciela. TAK
Definicja pojecia sasiedztwa nie zalezy od rodzaju rozwiazywanego problemu. NIE
Definicja sasiedztwa wymaga wykorzystania odleglosci na plaszczyznie. NIE
Dwa rozne chromosomy nigdy nie buduja tego samego rozwiazania. NIE
Dwa zbiory rozmyte nie moga miec w tym samym punkcie niezerowych wartosci. NIE
Funkcja aktywacji w klasycznych neuronach jest nierosnaca. NIE
Funkcja przynaleznosci do zbioru rozmytego osiaga dowolne wartosci z przedzialu [0,1]. TAK
Funkcja przynaleznosci do zbioru rozmytego to to samo, co rozklad prawdopodobienstwa. NIE
Funkcja XOR jest jedyna funkcja logiczna, jakiej nie da sie zrealizowac za pomoca pojedynczego perseptronu o dwoch wejsciach. NIE
Gdyby wielowastwowa siec neuronowa byla wyposazona w liniowa funkcje aktywacji, mozna by ja zastapic jedna warstwa neuronow. TAK
Jeden krok w metodzie wspinaczki polega na przeszukiwaniu rozwiazan podobnych do aktualnego w celu wybrania najlepszego z nich. TAK
Jednokierunkowa wielowarstwowa siec neuronowa moze z dowolna dokladnoscia przyblizyc dowolna funkcje ciagla. TAK
Jesli pewien szczegolny przypadek problemu X jest NP-trudny, to sam problem X jest NP-trudny. TAK
Jesli waga i-tego wejscia neuronu wynosi 0, wowczas stan wyjscia tego neuronu nie zalezy od i-tego sygnalu wyjsciowego. TAK
Jezeli siec neuronowa (po jednym cyklu uczenia metoda wstecznej propagacji) otrzyma na wejsciu obiekt identyczny z obiektem z probki treningowej to jej odpowiedz bedzie na perno prawidlowa. NIE
Krzyzowanie to operacja ktora nalezy zdefiniowac na nowo w przypadku wykorzystania nietypowych sposobow reperezentacji chromosomow w algorytmie genetycznym. TAK
Maszyna Turinga nie zawsze zatrzymuje sie po znanej z gory liczbie krokow. TAK
Maszyna Turinga zawsze zatrzymuje sie po znanej z gory liczbie krokow. NIE
Metoda odwracania dystrybuanty polega na przepuszczaniu wartosci bledu przez siec neuronowa w strone do wyjscia do wejscia. NIE
Metoda zachlanna to sposob pozwalajacy omijac optima lokalne. NIE
Metody grupowania (clustering) sluza do obliczania gradientu w algorytmie wstecznej propagacji. NIE
Metody zachlanne nigdy nie generuja globalnego rozwiazania problemow NP-trudnych. NIE
Metody zachlanne pozwalaja na dokladne rozwiazanie problemow NP-trudnych w czasie wielomianowym. NIE
Minimalne pokrycie wierzcholkowe grafu to problem NP-trudny. TAK
Nauka sieci neuronowej polega na zmianie wag neuronow. TAK
Nauka siesi neuronowej polega na znalezieniu wlasciwej kolejnosci, w jakiej neurony powinny otrzymywac informacje. NIE
Nauka z nauczycielem nie polega na bezposrednim ustalaniu wag przez uzytkownika. TAK
Nauka z nauczycielem polega na bezposrednim ustalaniu wag przez uzytkownika. NIE
Nauka z nauczyielem polega na tym, ze dysponujemy zarowno danymi wejsciowymi, jak i oczekiwanym stanem wyjsciowym. TAK
Niedeterministyczna maszyna Turinga dopuszcza kilka roznych sposobow dzialania w tej samej sytuacji. TAK
Niedeterministyczna maszyna Turinga potrafi rozwiazac problemy NP-zupelne w czasie wielomianowym. TAK
Niedeterministyczna maszyna Turniga nie potrafi rozwiazac problemow NP-zupelnych w czasie wielomianowym. NIE
Odczytany z tasmy symbol i aktualny stan wystarczaja do jednoznacznego okreslenia nastepnego kroku deterministycznej maszyny Turinga. TAK
Parametr temperatury w algorytmie wychladzania sluzy posrednio do regulowania prawdopodobienstwa wyjscia algorytmu z optimum lokalnego. TAK
Perceptron o dwoch wejsciach moze byc reprezentowany jako pewna prosta (lub polplaszczyzna). TAK
Po wyuczeniu sieci neuronowej na pewnym zbiorze przykladow, moga byc one powtornie uzyte w kolejnym stadium nauki. TAK
Pojedynczy perceptron o 3 wejsciach moze symulowac dowolna 3-argumntowa funkcje logiczna. NIE
Problem minimalnego pokrycia kolumnowego macierzy binarnej jest NP-trudny. TAK
Problem SAT (spelnialnosci formul logicznych) jest nierozwiazywalny w skonczonym czasie. NIE
Problemow NP-trudnych niegdy nie rozwiazemy dokladnie niezaleznie od wielkosci danych wejsciowych. NIE
Problemy klasy P sa rozwiazywalne za pomoca niedeterministycznej maszyny Turinga. TAK
Problemy NP-zupelne to pdzbior problemow z klasy NP. TAK
Problemy NP-zupelne to podzbior problemow klasy NP. TAK
Programowy generator liczb pseudolosowych w komputerez jest okresowy. TAK
Przeszukiwanie wiazkowe polega na wielokrotnym strosowaniu twierdzenia o schematach. NIE
Przeszukiwanie wiazkowe prowadzi do wykladnieczego wzrostu liczby badanych rozwiazan. NIE
Przeszukiwanie wiazkowe to pewne uogolnienie algorytmu zachlannego. TAK
SAT jest problemem polegajacym na znalezieniu optymalnej kolejnosci wykonywania dzialan podczas liczenia wartosci formuly logicznej. NIE
Sigmoidalna funkcja aktywacji neuronow zapewnie ze wartosc wyjsciowa zawsze rosnie jesli rasna wartosci na wejsciu sieci. TAK
Skladnikiem stanu wzbudzenia neuronu jest iloczyn skalarny wektora sygnalow wejsciowych i wektora wag. TAK
Sterowanie rozmyte ulatwia wykorzystanie nieprecyzyjnej wiedzy ekspertow. TAK
Szczegolnym przypadkiem zbioru rozmytego jest zwykly zbior. TAK
W algorymie wychladzania rozwazane jest dzialanie poprawiajace aktualne rozwiazanie. NIE
W algorytmie wychladzania relacja sasiedztwa rozwiazan nie powinna byc spojna. NIE
W algorytmie wychladzania rozwazamy wylacznie dzialania poprawiajace aktualne rozwiazanie. NIE
W metodzie przeszukiwania wiazkowego w kazdym kroku liczbe rozwazanych rozwiazan ogranicza sie do pewnej stalej wartosci. TAK
W przypadku skokowej funkcji aktywacji do nauki neuronu stosuje sie typowy algorytm wstecznej propagacji. NIE
W sieciach Hopfielda (pamieciach asocjacyjnych) rozwiazanie znajduje sie przez tworzenie w pamieci listy wyjsc odwiedzonych (zabronionych). NIE
W sieciach Kohenena neurony jednej warstwy bywaja ze soba polaczone. TAK
Wejscie neuronu moze przyjmowac wylacznie dodatnie wartosci. NIE
Wielowastwowa siec neuronowa moze miec wiecej wyjsc niz wejsc. TAK
Wybiebierajac drogi losowo mamy szanse kiedys znalezc najkrotsza trase w problemie komiwojazera. TAK
Wybierajac drogi losowo mamy szanse kiedys znalezc najkrotsza trase w problemie komiwojazera. TAK
Wybierajac drogi losowo nigdy nie mamy szansy znalezc najkrotszej trasy w problemie komiwojazera. NIE
Zmiany wag w algorytmie wstecznej propagacji odbywaja sie losowo, zgodnie z rozkladem prawdopodobienstwa. NIE
Znalezienie w grafie kliki rzedu 2 jest problemem NP-zupelnym. NIE
